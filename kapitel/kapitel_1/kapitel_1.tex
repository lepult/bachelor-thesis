\newpage
\section{Grundlagen}\label{Grundlagen}
Fehlender-Text

\subsection{Service Roboter}
In den letzten Jahren haben Service Roboter in verschiedenen Branchen an Bedeutung gewonnen. Ein Grund hierfür ist der technische Fortschritt der Robotik, KI, Big Data, Kameras, Sensoren und Spracherkennung \cite[S.~424]{Paluch2020}. Dieser Abschnitt gibt einen kurzen Überblick über Service Roboter im allgemeinen und eine Einführung in die Funktionen der Roboter, die in dieser Arbeit eingesetzt werden. Auch wird das System beschrieben, über das der Prototyp mit den Robotern kommuniziert.

\subsubsection{Definition}
In wissenschaftlichen Arbeiten wird mit vielen verschiedenen Definitionen für Service Roboter gearbeitet. In dieser Arbeit wird die Definition aus der ISO Norm 8373:2021 \cite[Kap.~3]{ISO2021} verwendet. Nach dieser handelt es sich bei Service Robotern um Roboter die im privaten oder professionellen Gebrauch nützliche Aufgaben für Menschen erledigen. Hierbei werden Service Roboter von Industrierobotern und Medizinrobotern abgegrenzt. Die \ac{IFR} \cite{IFR2024} ergänzt die Voraussetzung, dass Service Roboter voll- oder zumindest teilautonom handeln können. Unter professionellem Gebrauch versteht man den kommerziellen Einsatz \cite[S.~4]{GonzalezAguirre2021}, unter anderem im Gesundheitswesen, in der Landwirtschaft und im Tourismus \cite[S.~9]{GonzalezAguirre2021}.

\subsubsection{Einsatzmöglichkeiten}
Service Roboter werden bereits in vielen Bereichen eingesetzt. So gibt es verschiedene Beispiele in denen Service Roboter in Hotels für den Gästeempfang, Check-in und Gepäcklieferung eingesetzt werden. Auch werden Sie an Flughäfen für die Beratung von Reisenden, Scannen von Boardingpässen, Check-in, Bodenreinigung und Patrouilliengänge genutzt. In der Pflege helfen Service Roboter den Pflegern beim Heben von Patienten und durchführen von Übungen mit Patientengruppen. Auch können Roboter in der Pflege angenehme Gespräche starten \cite[S.~425-427]{Paluch2020}. Aufgaben mit geringer kognitiver und emotionaler Komplexität können Service Roboter hierbei vollautonom und ohne Aufsicht durch einen Menschen durchführen \cite[S.~429]{Paluch2020}. Hierbei handelt es sich beispielsweise um Aufgaben wie Staubsaugen, Rasenmähen oder Gepäcklieferung. Für komplexere Aufgaben braucht es die Aufsicht oder Unterstützung von Menschen, wodurch diese nur teilautonom ausgeführt werden.

Service Roboter, die im Kontakt mit Kunden eingesetzt werden, bieten verschiedene mögliche Vorteile, die aber immer abgewägt werden müssen. Beispielsweise können Roboter Emotionen vorspielen, die von Kunden aber als unauthentisch erkannt werden. Dafür können Roboter durchgängig freundlich sein und können nicht so wie Menschen unter emotionalem Burnout leiden \cite[S.~427]{Paluch2020}. 

\subsubsection{Pudu Robotics}
% TODO erwähnen das Roboter eine eingestellte Ladestation haben.
Wie erwähnt, beschäftigt sich diese Arbeit mit Robotern von Pudu. Pudu stellt Service Roboter her, die vor allem für verschiedene Zwecke in der Gastronomie eingesetzt werden können. Die Modelle sind hierbei auf unterschiedliche Funktionen, wie das Begrüßen von Gästen, das Liefern bestellter Speisen und Getränke, das Zurückbringen dreckigen Geschirs und das Putzen des Bodens spezialisiert \cite{PUDU2024}.

Damit die Roboter diese Funktionen ausführen können, müssen sie eigenständig durch komplexe, sich ändernde Umgebungen navigieren können. Das eigenständige Navigieren lässt sich in die Teilfunktionen die Positionsfindung, Wahrnehmung und Routenplanung aufteilen, wobei die Positionsfindung eine Schlüsselrolle spielt \cite{Nature2022}. Zur Positionsfindung erstellen sich die Roboter mit \ac{VSLAM} eine Karte ihrer Umgebung. Bei einer Fläche von 1000 Quadratmetern kann das eine Stunde dauern. Während Roboter normalerweise platzierte Markierungen brauchen, können sich die Pudu Roboter mithilfe einer nach oben gerichteten Kamera an der Zimmerdecke orientieren.\cite{Pudu2023} Durch weitere Kameras und Sensoren können die Pudu Roboter ihre Umgebung wahrnehmen\cite{Nature2022}.

\subsubsection{Bot Control Backend}\label{sec:BotControlBackend}
Im Rahmen dieser Arbeit wird eine bereits existierende Schnittstelle zwischen den Pudu Robotern und der prototypischen Webanwendung genutzt. Diese Schnittstelle ist das sogenannte \ac{BCB}. In diesem Abschnitt wird die Kommunikation zwischen dem \ac{BCB} und den Pudu Robotern erläutert. Die folgenden Informationen zum Service Framework von Pudu, das zur Kommunikation zwischen Robotern und \ac{BCB} genutzt wird, stammen aus dem SDK Guidance Document von Pudu \cite{PuduSDK}. Das Dokument steht nicht im Internet zur Verfügung und bietet keine genaueren Informationen zur MQTT basierten Kommunikation zwischen Microservice, PUDU Cloud und Robotern.

Die Abbildung \ref{fig:BotControlBackendCommunication} veranschaulicht die Kommunikation zwischen dem \ac{BCB} und den Robotern. Wie man in der Abbildung sieht hat das \ac{BCB} nur eine direkte Verbindung zum Node.js Microservice, welches wiederum über die PUDU Cloud mit den Robotern kommuniziert. Über \gls{HTTP}-Anfragen an den Microservice können Befehle verschickt und Daten abgefragt werden. Die Anfragen werden vom Microservice via \gls{MQTT} an die PUDU Cloud weitergeleitet. Anfragen die nicht an die Roboter weitergeleitet werden müssen, weil die angefragten Daten in der PUDU Cloud liegen, werden auf dem gleichen Weg direkt beantwortet. Muss mit den Robotern kommuniziert werden, dann wird die Anfrage von der PUDU Cloud über \gls{MQTT} an die relevanten Roboter weitergeleitet, die diese dann beantworten. Die Roboter können auch unaufgefordert Ereignisse an das \ac{BCB} kommunizieren. Hierfür muss das \ac{BCB} eine Adresse für einen bestimmten Ereignistyp im Microservice als \gls{Webhook} registrieren. Tritt das entsprechende Ereignis auf, schickt der Roboter diese Information via \gls{MQTT} über die PUDU Cloud an den Microservice. Dieser schickt daraufhin eine HTTP-Anfrage an die registrierte Adresse im \ac{BCB}.

\begin{figure}[H]
\caption{Kommunikation zwischen Bot Control Backend und Robotern}\label{fig:BotControlBackendCommunication}
\includegraphics[width=0.9\textwidth]{BotControlBackend Diagramm}
\\
Quelle: In Anlehnung an Pudu \cite[S.~4]{PuduSDK}
\end{figure}

Das \ac{BCB} dient nicht nur als Schnittstelle zu den Pudu Robotern, sondern abstraiert auch neue Funktionen aus denen die Pudu bietet. Zum können Roboter durch das \ac{BCB} über einen Fahrstuhl zu einem Lieferpunkt in einem anderen Stockwerk fahren. Zum anderen kann der Roboter vor einer geschlossenen Tür halten, diese öffnen und dann weiter fahren. Es gibt verschiedene Daten, die von den Robotern abgerufen werden und relevant für den Prototyp sind. So gibt es die Roboterposition in Relation zur mit \ac{VSLAM} generierten Karte. Zudem gibt es die Positionen der relevanten Standorte wie Lieferpunkte und Ladestation. Neben diesen Positionen gibt es zudem die Pfade, an denen sich die Roboter bei der Fahrt orientieren und virtuelle Wände, die manuell platziert werden müssen, damit bestimmte Bereiche nicht durchfahren werden. Beispielsweise ergibt es Sinn, Treppen als virtuelle Wände zu markieren, damit diese nicht versehentlich angefahren werden.

\subsection{Webanwendungen}
% Plattformunabhängigkeit mit Quelle erwähnen
Fehlender-Text

\subsubsection{Technologien und Softwarebibliotheken}\label{sec:WebTechnologies}
Fehlender-Text
% HTML erklären
% Typescript erklären => Javascript
% SCSS erklären => CSS
% React erklären
% React Redux erwähnen
% Build erklären

\subsubsection{chayns}\label{sec:Chayns}
Fehlender-Text
% chayns-Seite erläutern
% chayns-Application erläutern
% UAC-Gruppen erläutern
% Admin-Modus erläutern
% npx create-chayns-app
% chayns-components
% chayns-api
% chayns.space erläutern
% websocket-service erwähnen

\subsection{3D Modelle}
In diesem Abschnitt wird eine kurze Einführung zu 3D-Modellen gegeben. Danach werden verschiedene Methoden vorgestellt, die sich zum Erzeugen von 3D-Gebäudemodellen eignen. Zuletzt wird erklärt wie 3D-Modelle im Web eingebunden werden können. Ein direkter Vergleich der Methoden folgt in einem späteren Kapitel.

% TODO Nur polygonale Modelle erklären (Quelle % Parisi S 8-16)
Unter 3D-Modellen fällt ein breites Spektrum an Methoden zur dreidimensonalen Modellierung. So gibt es unter anderem polygonale 3D-Modelle und Punktwolken. Polygonale 3D-Modelle stellen die Fläche von Objekten mithilfe von Konten und Kanten dar. 

Punktwolken haben keine Kanten, sondern nur eine Vielzahl an Farbpunkten, die das Modell in ihrer Menge ohne Flächen bilden. Punktwolken haben in der Regel eine höhere Genauigkeit und mehr Details. Dafür haben Punktwolken aber auch einen höheren Speicherverbrauch. Im folgenden Kapitel werden kurze Ladezeiten und geringer Speicherverbrauch als nicht-funktionale Anforderung genannt. Aus diesem Grund sind Punktwolken nicht weiter relevant für diese Arbeit. Es gibt insbesondere Fotogrammetriemethoden die Punktwolken erzeugen. Diese sind im folgenden auch nicht weiter relevant. Polygonale 3D-Modelle - im folgenden einfach zu 3D-Modellen abgekürzt - haben einen geringeren Speicherverbrauch, sind dafür aber auch nicht so präzise. Für die Zwecke dieser Arbeit ist die Präzision aber mehr als ausreichend.

\subsubsection{Generierung}
Es gibt verschiedene Methoden, mit denen 3D Gebäudemodelle erzeugt werden können.

\paragraph{Fotogrammetrie}

Die Fotogrammetrie beschäftigt sich damit Messungen aus einer Vielzahl an zweidimensonalen Bildern abzuleiten. So lassen sich präzise 3D-Modelle erzeugen.\cite[S.~19]{Aber2010} Die Kameras neuerer Handys sind so gut, dass sie sich für Fotogrammetrie eignen \cite{Cohrs2021}. Der Prozess der Fotogrammetrie kann in mehrere Schritte aufgeteilt werden. Zunächst muss man die Aufnahmen planen. Man sollte auf gleichmäßige Belichtung, das Vermeiden von reflektiven und transparenten Flächen und das Vermeiden von Bewegung innerhalb der Szene achten. Bei der Aufnahme sollte man darauf achten, dass man die richtigen Kameraeinstellungen nutzt. Relevante Kameraeinstellungen sind unter anderem ISO, Belichtungszeit und Weißabgleich. Während die Bilder aufgenommen werden sollten die Einstellungen nicht geändert werden. Außerdem muss darauf geachtet werden, dass sich aufeinander folgende Bilder immer überschneiden.\cite{Cohrs2021b} Zuletzt kann man die Aufnahmen Verarbeiten. Hierfür benötigt man spezialisierte Software, die in der Nutzung kompliziert sein kann. Auch benötigt man leistungsfähige Hardware in der Form einer guten Grafikkarte sowie ausreichend freien Speicherplatz.\cite{Cohrs2021c}

\paragraph{LiDAR Scanning}
Im Gegensatz zur Fotogrammetrie wird bei \ac{LiDAR} ein aktiver Sensor genutzt. Es wird Licht in Form eines puslierenden Lasers ausgestrahlt und mit einem Scanner wieder eingefangen. Mithilfe der Reflektion lassen sich so Distanzen zu Punkten berechnen. Zusammen mit zusätzlicher aufgenommenen Daten lassen sich 3D-Modelle erzeugen. Seit 2020 baut Apple \ac{LiDAR} in mobile Geräte ein. Hiervon wird sich unter anderem eine erhöhte Bildqualität erhofft. Gleichzeitig ermöglicht \ac{LiDAR} aber auch das Scannen von Objekten.\cite{Fenstermaker2022} Für diesen Zweck gibt es mittlerweile verschiedene Apps, die den \ac{LiDAR} Scanner an den Geräten einsetzen, wie Canvas \cite{Canvas2023}, Polycam \cite{Polycam2024} und Scaniverse \cite{Scaniverse2024}. Diese Apps versprechen die Generierung von 3D-Modellen mit geringem Aufwand.

\paragraph{KI gestützte Methoden}
Es gibt verschiedene KI-Modelle, die darauf trainiert sind mithilfe von wenigen Bildern ein 3D-Gebäudemodell zu generieren. Eines dieser Modelle ist Plan2Scene. Als Eingabe braucht es einen Raumplan eines Gebäudes und Bilder der einzelnen Räume die den Räumen im Raumplan zugeordnet sind. Mithilfe des Raumplans wird dann ein 3D Modell mit 3D-Objekten für bestimmte Möbel generiert. Aus den Bildern werden monotone Texturen für Wänden, Böden und Zimmerdecken der einzelnen Räume generiert.\cite[S.~10733]{Plan2Scene2021} Das Rent3D Modell funktioniert ähnlich, statt generierten Texturen bekommen Wände und Böden aber stattdessen einfach die Bildaufnahmen als Textur \cite[S.~3413]{Rent3D2015}.

\subsubsection{Einbindung im Web}
Die Einbindung von 3D-Modellen wird im Web durch \ac{WebGL} und WebGPU ermöglicht. Während \ac{WebGL} für lange Zeit der etablierte Standard war, gewinnt WebGPU seit der Veröffentlichung im Jahr 2021 an Popularität.

\paragraph{WebGL}
\ac{WebGL} wurde 2011 durch die Khronos Group entwickelt und ist eine Javascript-API mit der 3D-Grafiken im Webbrowser ohne zusätzliche Plugins dargestellt werden können. Die 3D-Grafiken können hierbei hardwarebeschleunigt, also über den Einsatz spezialisierter Hardware wie einer \ac{GPU} angezeigt werden. Hierdurch wird eine hohe Leistungsfähigkeit ermöglicht, solange ein Gerät hardwarebeschleunigung unterstützt. Durch die Integration mit HTML und Javascript können 3D-Grafiken dynamisch in Webseiten eingebettet werden. Da \ac{WebGL} auf offenen Webstandards basiert, ist es in allen Browsern plattformunabhängig sowohl an Desktop- als auch an Mobilgeräten nutzbar.\cite[S.~17-19]{Parisi2014} WebGPU bietet wie WebGL das hardwarebeschleunigte Anzeigen von 3D-Grafiken. Zusätzlich bietet WebGPU aber auch eine bessere Leistung und erweiterte Funktionen.\cite{WebGPU} Entwicklern steht eine Vielzahl an Frameworks zur Verfügung die auf \ac{WebGL} oder WebGPU basieren, die die Entwicklung vereinfachen und beschleunigen.\cite{Seguin2024}

\paragraph{\deckgl{}}
DieDas Framework \deckgl{} wurde 2016 von Uber als Open Source Projekt veröffentlicht\cite{Visgl}. Das Framework basiert auf \ac{WebGL}, wobei ab der kommenden Version 9.0.0 WebGPU genutzt werden soll\cite{Green2022}. Mit \deckgl lassen sich hochperformante interaktive Karten und Geovisualisierungen mit tausenden bis millionen Datenpunkten im Web einbinden. Da das Framework auf React ähnlichen Programmierparadigmen basiert eignet es sich besonders für die Einbindung in React Anwendungen. Das Framework funktioniert nach dem \ac{PIL} Paradigma. So werden Datenpunkte gruppiert in einer Ebene dargestellt, die mindestens ein grundlegendes visuelles Element nutzt. So kann es sich bei diesen grundlegenden Elementen um Kreise, Rechtecke und Linien aber auch komplexere teilweise auch dreidimensonale Elemente handeln. Diese Elemente werden innerhalb der Ebene auf Basis der Datenpunkte und deren Attribute beispielsweise positioniert, skaliert und gefärbt. Die Ebenen können können übereinenander gestapelt werden und somit in Kombination angezeigt werden, was auch die Namensquelle des Frameworks ist, denn im englischen heißt Stapel deck.\cite[S.~2]{YangWang2019} Das Framework bietet verschiedene vordefinierte Ebenen, wie die IconLayer \cite{DeckglIconLayer}, die Bilder als grundlegende visuelle Elemente nutzt. So können einem oder mehreren Datenpunkten ein Bild und eine Position zugewiesen werden. In dem Beispiel aus Abbildung \ref{fig:IconLayerExample} wird die IconLayer - in Kombination mit einer Basisebene zur Darstellung der Weltkarte - genutzt um die Positionen aller bekannten Meteoritenlandungen auf der Erde anzuzeigen.

\begin{figure}[H]
    \caption{IconLayer Beispiel}\label{fig:IconLayerExample}
    \includegraphics[width=0.9\textwidth]{IconLayer Example.png}
    \\
    Quelle: OpenJS Foundation \cite{DeckGlMeteorites}
\end{figure}

Weitere für diese Arbeit relevante vordefinierte Ebenen sind die SimpleMeshLayer \cite{DeckglSimpleMeshLayer} und ScenegraphLayer \cite{DeckglScenegraphLayer} für die Anzeige von 3D-Modellen und die PathLayer für das Anzeigen von Pfaden. Es können auch neue Ebenen entwickelt werden, was für diese Arbeit aber nicht relevant ist, da die Auswahl an vordefinierten Ebenen ausreicht. Weitere wichtige Elemente die \deckgl{} bietet sind die Controller Klasse \cite{DeckglController}, mit der die Navigation auf der Karte konfiguriert werden kann und die Viewport Klasse \cite{DeckglViewport} mit der die Navigation gesteuert werden kann.

\subsection{Softwarequalität}
"Unter Softwarequalität versteht man die Gesamtheit der Merkmale und Merkmalswerte eines Softwareprodukts, die sich auf dessen Eignung beziehen, festgelegte oder vorausgesetzte Erfordernisse zu erfüllen" \cite[S.~257]{Balzert1998}. So ergibt sich die Softwarequalität aus der Erfüllung der definierten Anforderungen und Erwartungen und zielt darauf ab den Bedürfnissen der Benutzer gerecht zu werden. Für die Bestimmung der Softwarequalität gibt es verschiedene Merkmale die ausgewertet werden können. Nach dem ISO-Standard ISO/IEC 25010 gibt es acht Produktqualitätsmerkmale \cite{ISO25010}, die auch in der Abbildung \ref{fig:SoftwareQuality} aufgelistet sind. Die Merkmale Effizienz und Benutzbarkeit haben Relevanz für diese Arbeit, da diese direkt durch die Forschungsfrage gefordert werden und auch die funktionale Eignung ist relevant, da diese die Erfüllung der funktionalen Anforderungen abdeckt, die in Kapitel \ref{sec:FunctionalRequirements} definiert werden. Währenddessen haben die restlichen Mekrmale weniger Releavanz, da im Rahmen dieser Arbeit nur ein Prototyp entwickelt wird, der nicht die Ansprüche an ein Produktivsystem erfüllen muss. Im Folgenden werden die drei relevanten Merkmale genauer erläutert.
% TODO Quelle ISO 25010

\begin{figure}[H]
    \caption{Qualitätsmerkmale}\label{fig:SoftwareQuality}
    \includegraphics[width=0.9\textwidth]{Qualitaetsmerkmale.png}
    \\
    Quelle: TODO
\end{figure}
% TODO Quelle hinzufügen

\subsubsection{Benutzbarkeit}
Die Benutzbarkeit wird nach ISO 25010 in sechs Kriterien aufgeteilt: angemessene Erkennbarkeit, Erlernbarkeit, Bedienbarkeit, Toleranz gegenüber Anwenderfehlern, Ästhetik der Benutzeroberfläche und Barrierefreiheit.
% TODO Quelle ISO 25010
Mithilfe dieser Merkmale soll bewertet werden können wie einfach und angenehm ein Produkt für einen Nutzer zu bedienen ist.

\paragraph{Usability Heuristics}
Die zehn Usability Heuristics von Nielsen sind grundlegende Richtlinien zur Bewertung der Benutzerfreundlichkeit von Softwareprodukten und Websites. Während der Entwicklung können diesen Richtlinien berücksichtigt werden, um die Benutzerfreundlichkeit zu verbessern. Bis auf die Barrierefreiheit decken die Usability Heuristics alle Kriterien der Benutzbarkeit nach ISO 25010 ab. Zwei der Usability Heuristics sind die Übereinstimmung zwischen dem System und der realen Welt, um die Lernkurve zu reduzieren und die Einhaltung von Konsistenz und Standards, damit Elemente möglichst selbsterklärend sind.
% TODO Quelle Usability Heuristics
Eine subjektive Bewertung der Einhaltung dieser Richtlinien durch die Entwickler ist unzureichend um die Benutzerfreundlichkeit zu bewerten. Stattdessen eignet sich hier ein Expertenreview oder Usability Tests besser.

\paragraph{Usability Tests}
Usability Tests werden durchgeführt, damit die Benutzerfreundlichkeit eines Produkts bewertet werden kann. Hierfür werden Testpersonen bei der Nutzung des Produkts beobachtet. Die Testpersonen spielen hierbei zuvor entwickelte Anwendungsszenarien durch. Bei den Testpersonen sollte es sich um potenzielle Benutzer des Produkts handeln.\cite[S.~22]{Dumas.1999}. Nach der Durchführung der Tests werden die gesammelten Beobachtungen auf Probleme und Schwachstellen im Produkt ausgewertet. Die Tests können entweder quanitativ oder qualitativ durchgeführt werden. Bei quantitativen Usability Tests werden verschiedene Metriken, wie die Durchführungszeit oder die Rate der erfolgreichen Durchführung von Aufgaben gesammelt.
Mit Usability Tests lässt sich die Benutzerfreundlichkeit eines Produkts bewerten, indem Benutzer bei der Nutzung beobachtet werden und diese Beobachtungen. Diese Metriken zeigen im Vergleich zu den Ergebnissen früherer oder zukünftiger Tests, wie sich die Benutzerfreundlichkeit mit der Zeit entwickelt hat. Bei qualitativen Usability Tests werden Testpersonen bei der Interaktion mit dem Produkt beobachtet, wodurch sich Designmerkmale identifizieren lassen, die gut oder schlecht zu bedienen sind.\cite{Budiu.2017}. Qualitative Tests brauen einen Moderator, der die Testpersonen durch den Testprozess leitet. Gegebenenfalls gibt es auch weitere Beobachter, die nicht mit den Testpersonen interagieren.\cite{Moran.2019} Für qualitative Tests reicht eine Auswahl von fünf Testpersonen aus, um einen Großteil der Probleme zu finden. Mit einer zunehmenden Menge an Testpersonen sinkt das Return of Investment maßgeblich dadurch, dass immer weniger neue Fehler pro Testperson entdeckt werden.\cite{Nielsen.2012}

\subsubsection{Performance}

\subsubsection{Softwaretest}